FROM python:3.9-buster

ENV WORKDIR=/app
ENV PYTHONPATH=${PYTHONPATH}:${WORKDIR}
WORKDIR ${WORKDIR}

COPY . ${WORKDIR}
WORKDIR ${WORKDIR}/src/Services/crawler
RUN apt update && apt install git
RUN pip install -r requirements-scrapy.txt
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 CMD [ "curl", "http://localhost:6800/daemonstatus.json" ]

EXPOSE 6800
CMD scrapyd