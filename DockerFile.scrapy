FROM python:3.9-buster

ENV WORKDIR=/workspace
ENV PYTHONPATH=${PYTHONPATH}:${WORKDIR}
WORKDIR ${WORKDIR}

COPY src ${WORKDIR}/src
WORKDIR ${WORKDIR}/src/Services/crawler
RUN apt update && apt install git
RUN pip install -r requirements-scrapy.txt
RUN mkdir -p eggs/product_crawler && scrapyd-deploy --build-egg ./eggs/product_crawler/$(date +%s).egg

HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 CMD [ "curl", "http://localhost:6800/daemonstatus.json" ]
EXPOSE 6800

CMD scrapyd
ENTRYPOINT scrapyd
